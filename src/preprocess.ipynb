{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "RATING_FILE_NAME = dict({'movie': 'ratings.csv'})\n",
    "SEP = dict({'movie': ','})\n",
    "THRESHOLD = dict({'movie': 4})\n",
    "\n",
    "# extracting and converting data in appropriate manner\n",
    "def read_item_index_to_entity_id_file():\n",
    "    file = '../data/' + DATASET + '/item_index2entity_id.txt'\n",
    "    print('reading item index to entity id file: ' + file + ' ...')\n",
    "    i = 0\n",
    "    for line in open(file, encoding='utf-8').readlines():\n",
    "        item_index = line.strip().split('\\t')[0]\n",
    "        satori_id = line.strip().split('\\t')[1]\n",
    "        item_index_old2new[item_index] = i\n",
    "        entity_id2index[satori_id] = i\n",
    "        i += 1\n",
    "\n",
    "\n",
    "def convert_rating():\n",
    "    file = '../data/' + DATASET + '/' + RATING_FILE_NAME[DATASET]\n",
    "\n",
    "    print('reading rating file ...')\n",
    "    item_set = set(item_index_old2new.values())\n",
    "    user_pos_ratings = dict()\n",
    "    user_neg_ratings = dict()\n",
    "\n",
    "    for line in open(file, encoding='utf-8').readlines()[1:]:\n",
    "        array = line.strip().split(SEP[DATASET])\n",
    "\n",
    "        item_index_old = array[1]\n",
    "        if item_index_old not in item_index_old2new:  # the item is not in the final item set\n",
    "            continue\n",
    "        item_index = item_index_old2new[item_index_old]\n",
    "\n",
    "        user_index_old = int(array[0])\n",
    "\n",
    "        rating = float(array[2])\n",
    "        if rating >= THRESHOLD[DATASET]:\n",
    "            if user_index_old not in user_pos_ratings:\n",
    "                user_pos_ratings[user_index_old] = set()\n",
    "            user_pos_ratings[user_index_old].add(item_index)\n",
    "        else:\n",
    "            if user_index_old not in user_neg_ratings:\n",
    "                user_neg_ratings[user_index_old] = set()\n",
    "            user_neg_ratings[user_index_old].add(item_index)\n",
    "\n",
    "    print('converting rating file ...')\n",
    "    writer = open('../data/' + DATASET + '/ratings_final.txt', 'w', encoding='utf-8')\n",
    "    user_cnt = 0\n",
    "    user_index_old2new = dict()\n",
    "    for user_index_old, pos_item_set in user_pos_ratings.items():\n",
    "        if user_index_old not in user_index_old2new:\n",
    "            user_index_old2new[user_index_old] = user_cnt\n",
    "            user_cnt += 1\n",
    "        user_index = user_index_old2new[user_index_old]\n",
    "\n",
    "        for item in pos_item_set:\n",
    "            writer.write('%d\\t%d\\t1\\n' % (user_index, item))\n",
    "        unwatched_set = item_set - pos_item_set\n",
    "        if user_index_old in user_neg_ratings:\n",
    "            unwatched_set -= user_neg_ratings[user_index_old]\n",
    "        for item in np.random.choice(list(unwatched_set), size=len(pos_item_set), replace=False):\n",
    "            writer.write('%d\\t%d\\t0\\n' % (user_index, item))\n",
    "    writer.close()\n",
    "    print('number of users: %d' % user_cnt)\n",
    "    print('number of items: %d' % len(item_set))\n",
    "\n",
    "\n",
    "def convert_kg():\n",
    "    print('converting kg file ...')\n",
    "    entity_cnt = len(entity_id2index)\n",
    "    relation_cnt = 0\n",
    "\n",
    "    writer = open('../data/' + DATASET + '/kg_final.txt', 'w', encoding='utf-8')\n",
    "    for line in open('../data/' + DATASET + '/kg.txt', encoding='utf-8'):\n",
    "        array = line.strip().split('\\t')\n",
    "        head_old = array[0]\n",
    "        relation_old = array[1]\n",
    "        tail_old = array[2]\n",
    "\n",
    "        if head_old not in entity_id2index:\n",
    "            entity_id2index[head_old] = entity_cnt\n",
    "            entity_cnt += 1\n",
    "        head = entity_id2index[head_old]\n",
    "\n",
    "        if tail_old not in entity_id2index:\n",
    "            entity_id2index[tail_old] = entity_cnt\n",
    "            entity_cnt += 1\n",
    "        tail = entity_id2index[tail_old]\n",
    "\n",
    "        if relation_old not in relation_id2index:\n",
    "            relation_id2index[relation_old] = relation_cnt\n",
    "            relation_cnt += 1\n",
    "        relation = relation_id2index[relation_old]\n",
    "\n",
    "        writer.write('%d\\t%d\\t%d\\n' % (head, relation, tail))\n",
    "\n",
    "    writer.close()\n",
    "    print('number of entities (containing items): %d' % entity_cnt)\n",
    "    print('number of relations: %d' % relation_cnt)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # parser = argparse.ArgumentParser()\n",
    "    # parser.add_argument('-d', type=str, default='movie', help='which dataset to preprocess')\n",
    "    # args = parser.parse_args()\n",
    "    # DATASET = args.d              # select movie dataset\n",
    "\n",
    "    DATASET = 'movie'\n",
    "\n",
    "    entity_id2index = dict()\n",
    "    relation_id2index = dict()\n",
    "    item_index_old2new = dict()\n",
    "\n",
    "    read_item_index_to_entity_id_file()\n",
    "    convert_rating()\n",
    "    convert_kg()\n",
    "\n",
    "    print('done')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
